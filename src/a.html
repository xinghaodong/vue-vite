<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vue Audio Recorder</title>
    <!-- 引入 Vue 3 -->
    <script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>
    <!-- 引入 Tailwind CSS 用于美化 -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            font-family: 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
            background-color: #f3f4f6;
        }

        .recording-pulse {
            animation: pulse-red 1.5s infinite;
        }

        @keyframes pulse-red {
            0% {
                box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7);
            }

            70% {
                box-shadow: 0 0 0 10px rgba(239, 68, 68, 0);
            }

            100% {
                box-shadow: 0 0 0 0 rgba(239, 68, 68, 0);
            }
        }
    </style>
</head>

<body>

    <div id="app" class="min-h-screen flex items-center justify-center">
        <div class="bg-white p-8 rounded-xl shadow-lg w-full max-w-md text-center">
            <h1 class="text-2xl font-bold mb-6 text-gray-800">语音转 WAV 录制</h1>

            <!-- 状态展示 -->
            <div class="mb-8 flex justify-center items-center h-24">
                <div v-if="isRecording"
                    class="recording-pulse w-16 h-16 bg-red-500 rounded-full flex items-center justify-center text-white font-bold">
                    REC
                </div>
                <div v-else class="text-gray-400">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-16 w-16" fill="none" viewBox="0 0 24 24"
                        stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="1"
                            d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                    </svg>
                </div>
            </div>

            <div class="text-sm text-gray-500 mb-4" v-if="statusMsg">{{ statusMsg }}</div>

            <!-- 操作按钮 -->
            <div class="space-x-4">
                <button @click="startRecording" v-if="!isRecording"
                    class="bg-blue-600 hover:bg-blue-700 text-white font-semibold py-2 px-6 rounded-full transition duration-200">
                    开始录音
                </button>

                <button @click="stopRecording" v-if="isRecording"
                    class="bg-red-500 hover:bg-red-600 text-white font-semibold py-2 px-6 rounded-full transition duration-200">
                    停止并上传
                </button>
            </div>

            <!-- 调试：播放录制的音频 -->
            <div v-if="audioUrl" class="mt-6 p-4 bg-gray-50 rounded-lg">
                <p class="text-xs text-gray-400 mb-2">本地预览 (WAV):</p>
                <audio controls :src="audioUrl" class="w-full h-8"></audio>
                <div class="mt-2 text-xs text-green-600 break-all">
                    Blob Size: {{ blobSize }} bytes
                </div>
            </div>
        </div>
    </div>

    <script>
        const { createApp, ref } = Vue;

        // --- 模拟 audiobuffer-to-wav 库的功能 ---
        // 在真实项目中，你可以继续使用 import toWav from 'audiobuffer-to-wav'
        // 这里为了演示方便，手写了一个简易且健壮的 WAV 转换函数
        function audioBufferToWav(buffer, opt) {
            opt = opt || {};
            var numChannels = buffer.numberOfChannels;
            var sampleRate = buffer.sampleRate;
            var format = opt.float32 ? 3 : 1; // 3 = IEEE Float, 1 = PCM
            var bitDepth = format === 3 ? 32 : 16;

            var result;
            if (numChannels === 2) {
                result = interleave(buffer.getChannelData(0), buffer.getChannelData(1));
            } else {
                result = buffer.getChannelData(0);
            }

            return encodeWAV(result, format, sampleRate, numChannels, bitDepth);
        }

        function interleave(inputL, inputR) {
            var length = inputL.length + inputR.length;
            var result = new Float32Array(length);
            var index = 0;
            var inputIndex = 0;
            while (index < length) {
                result[index++] = inputL[inputIndex];
                result[index++] = inputR[inputIndex];
                inputIndex++;
            }
            return result;
        }

        function encodeWAV(samples, format, sampleRate, numChannels, bitDepth) {
            var bytesPerSample = bitDepth / 8;
            var blockAlign = numChannels * bytesPerSample;
            var buffer = new ArrayBuffer(44 + samples.length * bytesPerSample);
            var view = new DataView(buffer);

            /* RIFF identifier */
            writeString(view, 0, 'RIFF');
            /* RIFF chunk length */
            view.setUint32(4, 36 + samples.length * bytesPerSample, true);
            /* RIFF type */
            writeString(view, 8, 'WAVE');
            /* format chunk identifier */
            writeString(view, 12, 'fmt ');
            /* format chunk length */
            view.setUint32(16, 16, true);
            /* sample format (raw) */
            view.setUint16(20, format, true);
            /* channel count */
            view.setUint16(22, numChannels, true);
            /* sample rate */
            view.setUint32(24, sampleRate, true);
            /* byte rate (sample rate * block align) */
            view.setUint32(28, sampleRate * blockAlign, true);
            /* block align (channel count * bytes per sample) */
            view.setUint16(32, blockAlign, true);
            /* bits per sample */
            view.setUint16(34, bitDepth, true);
            /* data chunk identifier */
            writeString(view, 36, 'data');
            /* data chunk length */
            view.setUint32(40, samples.length * bytesPerSample, true);

            if (format === 1) { // PCM 16-bit
                floatTo16BitPCM(view, 44, samples);
            } else {
                writeFloat32(view, 44, samples);
            }

            return buffer;
        }

        function floatTo16BitPCM(output, offset, input) {
            for (var i = 0; i < input.length; i++, offset += 2) {
                var s = Math.max(-1, Math.min(1, input[i]));
                output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
        }

        function writeFloat32(output, offset, input) {
            for (var i = 0; i < input.length; i++, offset += 4) {
                output.setFloat32(offset, input[i], true);
            }
        }

        function writeString(view, offset, string) {
            for (var i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }
        // --- 结束 WAV 辅助函数 ---


        createApp({
            setup() {
                const isRecording = ref(false);
                const statusMsg = ref("点击开始录音");
                const audioUrl = ref(null);
                const blobSize = ref(0);

                let audioContext = null;
                let processor = null;
                let mediaStream = null;
                let audioChunks = []; // 存放 Float32Array 原始数据

                const startRecording = async () => {
                    try {
                        audioUrl.value = null; // 重置上一段录音
                        audioChunks = []; // 清空数据

                        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                        mediaStream = stream;

                        // 创建 AudioContext
                        audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        const source = audioContext.createMediaStreamSource(stream);

                        // 使用 ScriptProcessor (注意：这确实已废弃，但在现代浏览器中仍然有效，适合简单需求)
                        // 缓冲区大小 4096，1输入声道，1输出声道
                        processor = audioContext.createScriptProcessor(4096, 1, 1);

                        processor.onaudioprocess = (e) => {
                            // 获取 PCM 数据 (Float32Array)
                            const channelData = e.inputBuffer.getChannelData(0);
                            // 必须深拷贝 slice()，因为 buffer 会被重用
                            audioChunks.push(channelData.slice());
                        };

                        source.connect(processor);
                        processor.connect(audioContext.destination);

                        isRecording.value = true;
                        statusMsg.value = "正在录音...";

                    } catch (err) {
                        console.error('录音启动失败:', err);
                        statusMsg.value = "录音失败: " + err.message;
                    }
                };

                const stopRecording = () => {
                    if (!isRecording.value) return;

                    // 1. 停止处理节点（但先别关闭 AudioContext，我们需要它来创建 Buffer）
                    if (processor) {
                        processor.disconnect();
                        processor.onaudioprocess = null;
                    }

                    // 2. 停止麦克风流
                    if (mediaStream) {
                        mediaStream.getTracks().forEach(track => track.stop());
                    }

                    // 3. 数据合并处理 (关键修复步骤)
                    const totalLength = audioChunks.reduce((acc, chunk) => acc + chunk.length, 0);
                    const fullAudio = new Float32Array(totalLength);
                    let offset = 0;
                    for (const chunk of audioChunks) {
                        fullAudio.set(chunk, offset);
                        offset += chunk.length;
                    }

                    if (totalLength === 0) {
                        statusMsg.value = "未录制到声音数据";
                        isRecording.value = false;
                        return;
                    }

                    // 4. 创建真实的 AudioBuffer (这解决了你的 getChannelData 报错)
                    // 必须使用 audioContext 创建，因为它包含了采样率信息
                    const pcmBuffer = audioContext.createBuffer(1, totalLength, audioContext.sampleRate);
                    // 将合并好的数据填充进去
                    pcmBuffer.getChannelData(0).set(fullAudio);

                    // 5. 转 WAV
                    // 使用上面定义的辅助函数 (或者你的 import toWav from 'audiobuffer-to-wav')
                    // 传入真实的 AudioBuffer 对象，而不是普通对象
                    const wavArrayBuffer = audioBufferToWav(pcmBuffer);
                    const wavBlob = new Blob([wavArrayBuffer], { type: 'audio/wav' });

                    // 6. 清理并生成预览
                    blobSize.value = wavBlob.size;
                    audioUrl.value = URL.createObjectURL(wavBlob);

                    // 此时再关闭 Context
                    if (audioContext) audioContext.close();

                    isRecording.value = false;
                    statusMsg.value = "录音完成，准备上传";

                    // 7. 模拟上传
                    uploadAudio(wavBlob);
                };

                const uploadAudio = (blob) => {
                    // 模拟你的 sendAudioToStt 逻辑
                    console.log("准备上传 Blob:", blob);
                    const formData = new FormData();
                    formData.append('avatar', blob, 'voice.wav');
                    // axios.post(...)
                };

                return {
                    isRecording,
                    statusMsg,
                    startRecording,
                    stopRecording,
                    audioUrl,
                    blobSize
                };
            }
        }).mount('#app');
    </script>

</body>

</html>